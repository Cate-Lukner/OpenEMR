{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import textract\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- converted PDF file to txt format for better pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename ='sample3.pdf' \n",
    "\n",
    "pdfFileObj = open(filename,'rb')               #open allows you to read the file\n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)   #The pdfReader variable is a readable object that will be parsed\n",
    "num_pages = pdfReader.numPages                 #discerning the number of pages will allow us to parse through all the pages\n",
    "\n",
    "\n",
    "count = 0\n",
    "text = \"\"\n",
    "                                                            \n",
    "while count < num_pages:                       #The while loop will read each page\n",
    "    pageObj = pdfReader.getPage(count)\n",
    "    count +=1\n",
    "    text += pageObj.extractText()\n",
    "    \n",
    "#Below if statement exists to check if the above library returned #words. It's done because PyPDF2 cannot read scanned files.\n",
    "\n",
    "if text != \"\":\n",
    "    text = text\n",
    "    \n",
    "#If the above returns as False, we run the OCR library textract to #convert scanned/image based PDF files into text\n",
    "\n",
    "else:\n",
    "    text = textract.process('http://bit.ly/epo_keyword_extraction_document', method='tesseract', language='eng')\n",
    "\n",
    "    # Now we have a text variable which contains all the text derived from our PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.encode('ascii','ignore').lower() #Lowercasing each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'&\"$*anatomy of the somatosensory system7451/#615\\'0514;5;56\\'/%105+5651(5\\'05145+06*\\'5-+0#0&5\\'05145+0174#0&*\\'%\\'26145+06*\\'6*\\'51%#..\\'&%76#0\\'1754\\'%\\'26\\'..75#$1766\\'/2\\'4#674\\'#&\"$%24\\'5574\\'#0&(#%\\'6\\':674\\'#&\"$%#0&2#+0#&\"$%*\\'4\\'%\\'26145+0/75%.\\'5#0&,1+0652418+&\\'+0(14/#6+10cutaneous receptors\\'0514;+0(14/#6+10(41/#0&4#2+&.;#&#26+0)#((\\'4\\'065.\\'#&561#&,756/\\'061()4+2(14%\\'9*\\'01$,\\'%65#4\\'.+(*\\'5\\'#((\\'4\\'0654\\'5210&9+6*#$4+\\'($74561(#%6+10216\\'06+#.59*\\'01$,\\'%65/18\\'#5/#..6#0%\\'&74+0)6*\\'\\'#4.;56#)\\'51(.+(4\\'52105\\'61#&\"$%!&#&\"$%$#&\"$%\"$\"$$#&\"$%&#&\"$%&$\"\"&%\"#&\"$%&&#&\"$%!&\\'-!,%hairy skinglabrous skinepidermisdermispaciniancorpusclepapillary ridgesseptaruffinis corpusclehair receptormeissnerscorpusclesebaceousglandfree nerveendingmerkelsreceptor1..1\\'45+6;%#!%\")!&#\"%&\"!!!\"$%#!%#&\"$)&&%\")! \"&\"$%\\'##+%%&!\"%(%!%\"$+!!%\"$\"\\'#$\"\\'#\"&#\"$&\"!%\"&4#2+&.;#&#26+0)#((\\'4\\'06#%6+8+6;/75%.\\'(14%\\'+0%4\\'#5\\'54\\'d\\':+8\\'.;706+.6*\\')4+22\\'&1$,\\'%601.10)\\'4/187%*#4#2+&4\\'52105\\'61#6#%6+.\\'56+/7.75+5#%.\\'#4+0&+%#6+101(6*\\'41.\\'2.#;\\'&$;51/#615\\'0514;0\\'74105+0/16146+8+6;*\\'5.19.;#&#26+0),%#&\"$%#4\\'4\\'52105+$.\\'(14(14/#0&6\\':674\\'2\\'4%\\'2917.&$\\'\\':2\\'%6\\'&(144\\'%\\'26145/\\'&+#6+0)(14/2\\'4%\\'2\\'4-\\'.@54\\'%\\'26145#4\\'24\\'5\\'06#6*+)*&\\'05+6;+06*\\'&+)+65#0&#4170&6*\\'/176*//>1(5-+0574(#%#6.19\\'4&\\'05+6;+01\\'4).#$4175574(#%#0&#68\\'4;.19&\\'05+6;+0*#+4;*+5+00\\'48#6+105&\\'05+6;5*4+0-5241)4\\'55+8\\'.;9+6*6*\\'2#55#)\\'1(6+/\\'516*#6$;6*\\'#)\\'1(6*\\'&\\'05+6;+0/#0&+)+65+54\\'&7%\\'&610.+-\\'4#2+&.;#&#26+0)#:5.19.;#&#26+0)c$\\'454\\'5210&01610.;616*\\'6+#.+0&\\'06#6+101($76#.51615756#+0\\'&+0&\\'06#6+108%6+8#6+101(6*\\'4#2+&.;#&#26+0))+8\\'5#(\\'\\'.+0)1(9*+.\\'6*\\'5.19.;#&#26+0)\\'-!4\\'5210&616*\\'.#6#4#./18\\'/\\'0614nociceptors1%+%\\'26145*#8\\'(4\\'\\'0\\'48\\'6+10#..;5-+001%+%\\'26145#4\\'\\'+6*\\'4/\\'%*#014\\'%\\'26145rapidly adaptingslowly adapting74(#%\\'4\\'%\\'2614\\'26+8\\'c\\'.&#&\"$6\\'%\\'4\\'4-\\'.@\\'2\\'\\'2\\'26+8\\'c\\'.&564\\'6%*b14#&\"$%1.;/1&#.4\\'%\\'261454\\'5210&01610.;61+06\\'05\\'/\\'%*#0+%#.$76#.5161*\\'#6#0&6101:+175*\\'5\\'4\\'%\\'261454\\'5210&61/+076\\'270%674\\'51(6*\\'9+6*#4\\'52105\\'/#)0+67&\\'6*#6&\\'2\\'0&5106*\\'&\\')4\\'\\'1(6+557\\'&\\'(*\\';514\\'5210&616\\'/2\\'4#674\\'5+06*\\'4#0)\\'1(#0&%*#0)\\'6*\\'+44\\'52105\\'4#6\\'5#5#.+0\\'#4(70%6+101(+0)%1064#569+6*6*\\'5#674#6+0)4\\'52105\\'5&+52.#;\\'&$;\\'2#+05+)0#.5%#0$\\'5\\'2#4#6\\'&+061+0&+8+&7#.%%144\\'5210&+0)61&+((\\'4\\'066;2\\'51(0\\'48\\'c$\\'4575\\'&(1464#05/+66+0)6*\\'5\\'*\\'4#2+&.;6\\'&9*+%*1(6\\'0*#5*+)*52#6+#.+5%#..\\'&-$%&14+59\\'..+<\\'&#0&\\'#5+.;*\\'/7%*5.19\\'4*+)*.;#((6+8\\'%1/210\\'06+5%#..\\'&\"!14+6+52114.;.1%#.+<\\'&#0&2114.;*\\'6*+4&14##4+5+0)(41/8+5%/75%7.#674\\'#0&+5#.512114.;.1%#.+<%#0$\\'%*410+%#0&+51(6\\'0#551%+#6\\'&muscle spindles%#66\\'4\\'&6*417)*1768+467#..;\\'8\\'4;564+#6\\'&/75%.\\'+06*\\'$1&;#4\\'564\\'6%*4\\'%\\'26145%#..\\'&/75%.\\'*\\';#4\\'37+6\\'5+/2.\\'+0%105+56+0)1(#(\\'95/#../75%.\\'c$\\'459+6*#%#257.\\'5744170&+0)6*\\'/+&&.\\'6*+4&1(6*\\'*\\'5\\'c$\\'45#4\\'%#..\\'&+0%1064#56616*\\'14&+0#4;*\\'\\'0&51(6*\\'+064#(75#.c$\\'45#4\\'#66#%*\\'&61\\':64#(75#.51\\'8\\'46*\\'/75%.\\'+56*\\'+064#(75#.c$\\'45#4\\'#.51forcecontrolsignaldrivingsignallengthcontrolsignalloadexternalforcestendonorgansmuscle forcemusclelengthforce feedbacklength &velocityfeedbackforce (golgi tendon organ)spindlesgamma biaslength (secondary muscle-spindel afferents)length error (primary muscle-spindel afferents)velocity (primary muscle-spindel afferents)muscleinter-neurons\"\"#%\"$#&(\"$&#&\"!\"!&$\"\" \"(*\\'%\\'064#.4\\')+101(\\'#%*+064#(75#.c$\\'4*#5(\\'9/;1c.#/\\'065#0&+51064#%$76+6&1\\'5*#8\\'10\\'14/14\\'5\\'0514;\\'0&+0)5#22.+\\'&61 *\\'06*\\'%.\\'+56*\\'%\\'064#.2#461(6*\\'+064#(75#.c$\\'4+575%.\\'52+0&.\\'5#.514\\'%\\'+8\\'#/1614+00\\'4*\\'.#4)\\'/16140\\'741056*#65722.;\\':64#(75#./75%.\\'c$\\'45#4\\'%#..\\'& \"&\"$!\\'$\"!%9*+.\\'6*\\'5/#..\\'410\\'52.;+0)6*\\'%1064#%6+.\\'2146+1051(+064#(75#.c$\\'45#4\\'%#..\\'&!\\'$\"!%/16140\\'74105%#0.#6\\'6*\\'5\\'05+6+8+6;1(6*\\'/75%.\\'52+0&.\\'516*#66*+56+8+6joint receptors*\\',1+064\\'%\\'26145#4\\'.19/\\'%*#014\\'%\\'26145#0&*#8\\'$\\'\\'0&+8+&\\'&+061(174*\\';5+)0#.&+((\\'06%*#4#%6\\'4+56+%51(,1+06(70%6+10/18&+4\\'%6+10#0&52\\'\\'&1(/18*\\'(4\\'\\'4\\'%\\'26145146\\'2\\'2'\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-51ed67cfddfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'reactor'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m                               \u001b[0;31m#Total keywords in document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "keywords = re.findall(r'reactor',text)\n",
    "len(keywords)                               #Total keywords in document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(set(keywords)),columns=['keywords'])  #Dataframe with unique keywords to avoid repetition in rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Weightage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __TF: Term Frequency__, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n",
    "\n",
    "__TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).__\n",
    "\n",
    "- __IDF: Inverse Document Frequency__, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "\n",
    "__IDF(t) = log_e(Total number of documents / Number of documents with term t in it).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightage(word,text,number_of_documents=1):\n",
    "    word_list = re.findall(word,text)\n",
    "    number_of_times_word_appeared =len(word_list)\n",
    "    tf = number_of_times_word_appeared/float(len(text))\n",
    "    idf = np.log((number_of_documents)/float(number_of_times_word_appeared))\n",
    "    tf_idf = tf*idf\n",
    "    return number_of_times_word_appeared,tf,idf ,tf_idf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_times_word_appeared'] = df['keywords'].apply(lambda x: weightage(x,text)[0])\n",
    "df['tf'] = df['keywords'].apply(lambda x: weightage(x,text)[1])\n",
    "df['idf'] = df['keywords'].apply(lambda x: weightage(x,text)[2])\n",
    "df['tf_idf'] = df['keywords'].apply(lambda x: weightage(x,text)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>number_of_times_word_appeared</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>in</td>\n",
       "      <td>369</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>-5.910797</td>\n",
       "      <td>-0.088146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>re</td>\n",
       "      <td>258</td>\n",
       "      <td>0.010427</td>\n",
       "      <td>-5.552960</td>\n",
       "      <td>-0.057899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>at</td>\n",
       "      <td>247</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>-5.509388</td>\n",
       "      <td>-0.054996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>on</td>\n",
       "      <td>243</td>\n",
       "      <td>0.009821</td>\n",
       "      <td>-5.493061</td>\n",
       "      <td>-0.053945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>the</td>\n",
       "      <td>203</td>\n",
       "      <td>0.008204</td>\n",
       "      <td>-5.313206</td>\n",
       "      <td>-0.043590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>an</td>\n",
       "      <td>199</td>\n",
       "      <td>0.008042</td>\n",
       "      <td>-5.293305</td>\n",
       "      <td>-0.042571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>to</td>\n",
       "      <td>190</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>-5.247024</td>\n",
       "      <td>-0.040290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>or</td>\n",
       "      <td>167</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>-5.117994</td>\n",
       "      <td>-0.034542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>as</td>\n",
       "      <td>157</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>-5.056246</td>\n",
       "      <td>-0.032082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>java</td>\n",
       "      <td>135</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>-4.905275</td>\n",
       "      <td>-0.026763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>it</td>\n",
       "      <td>122</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>-4.804021</td>\n",
       "      <td>-0.023686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>is</td>\n",
       "      <td>110</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>-4.700480</td>\n",
       "      <td>-0.020896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>int</td>\n",
       "      <td>104</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>-4.644391</td>\n",
       "      <td>-0.019521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>-4.477337</td>\n",
       "      <td>-0.015923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>of</td>\n",
       "      <td>75</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-4.317488</td>\n",
       "      <td>-0.013086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>and</td>\n",
       "      <td>71</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>-4.262680</td>\n",
       "      <td>-0.012231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>no</td>\n",
       "      <td>70</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>-4.248495</td>\n",
       "      <td>-0.012019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>com</td>\n",
       "      <td>67</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>-4.204693</td>\n",
       "      <td>-0.011385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>for</td>\n",
       "      <td>65</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>-4.174387</td>\n",
       "      <td>-0.010966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>data</td>\n",
       "      <td>62</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>-4.127134</td>\n",
       "      <td>-0.010341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>are</td>\n",
       "      <td>60</td>\n",
       "      <td>0.002425</td>\n",
       "      <td>-4.094345</td>\n",
       "      <td>-0.009928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>applet</td>\n",
       "      <td>57</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>-4.043051</td>\n",
       "      <td>-0.009314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>hi</td>\n",
       "      <td>56</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>-4.025352</td>\n",
       "      <td>-0.009110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>obj</td>\n",
       "      <td>56</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>-4.025352</td>\n",
       "      <td>-0.009110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>but</td>\n",
       "      <td>55</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>-4.007333</td>\n",
       "      <td>-0.008907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    keywords  number_of_times_word_appeared        tf       idf    tf_idf\n",
       "194       in                            369  0.014913 -5.910797 -0.088146\n",
       "317       re                            258  0.010427 -5.552960 -0.057899\n",
       "880       at                            247  0.009982 -5.509388 -0.054996\n",
       "783       on                            243  0.009821 -5.493061 -0.053945\n",
       "690      the                            203  0.008204 -5.313206 -0.043590\n",
       "876       an                            199  0.008042 -5.293305 -0.042571\n",
       "25        to                            190  0.007679 -5.247024 -0.040290\n",
       "799       or                            167  0.006749 -5.117994 -0.034542\n",
       "878       as                            157  0.006345 -5.056246 -0.032082\n",
       "588     java                            135  0.005456 -4.905275 -0.026763\n",
       "636       it                            122  0.004930 -4.804021 -0.023686\n",
       "635       is                            110  0.004446 -4.700480 -0.020896\n",
       "345      int                            104  0.004203 -4.644391 -0.019521\n",
       "2        all                             88  0.003556 -4.477337 -0.015923\n",
       "789       of                             75  0.003031 -4.317488 -0.013086\n",
       "570      and                             71  0.002869 -4.262680 -0.012231\n",
       "887       no                             70  0.002829 -4.248495 -0.012019\n",
       "568      com                             67  0.002708 -4.204693 -0.011385\n",
       "761      for                             65  0.002627 -4.174387 -0.010966\n",
       "228     data                             62  0.002506 -4.127134 -0.010341\n",
       "527      are                             60  0.002425 -4.094345 -0.009928\n",
       "404   applet                             57  0.002304 -4.043051 -0.009314\n",
       "846       hi                             56  0.002263 -4.025352 -0.009110\n",
       "168      obj                             56  0.002263 -4.025352 -0.009110\n",
       "844      but                             55  0.002223 -4.007333 -0.008907"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('tf_idf',ascending=True)\n",
    "df.to_csv('Keywords.csv')\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Method - Using Gensim library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RequestsDependencyWarning: urllib3 (1.22) or chardet (2.3.0) doesn't match a supported version! [__init__.py:80]\n",
      "UserWarning: detected Windows; aliasing chunkize to chunkize_serial [utils.py:1197]\n"
     ]
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = keywords(text=text,split='\\n',scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>java basics</td>\n",
       "      <td>0.314014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>methods</td>\n",
       "      <td>0.247325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>method</td>\n",
       "      <td>0.247325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>applets</td>\n",
       "      <td>0.241786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>applet</td>\n",
       "      <td>0.241786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class</td>\n",
       "      <td>0.219800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>classes</td>\n",
       "      <td>0.219800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>objects</td>\n",
       "      <td>0.190636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>object</td>\n",
       "      <td>0.190636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>programs</td>\n",
       "      <td>0.163243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword     score\n",
       "0  java basics  0.314014\n",
       "2      methods  0.247325\n",
       "1       method  0.247325\n",
       "3      applets  0.241786\n",
       "4       applet  0.241786\n",
       "5        class  0.219800\n",
       "6      classes  0.219800\n",
       "7      objects  0.190636\n",
       "8       object  0.190636\n",
       "9     programs  0.163243"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(values,columns=['keyword','score'])\n",
    "data = data.sort_values('score',ascending=False)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Approach - Using RAKE (Rapid Automatic Keyword Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()\n",
    "r.extract_keywords_from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = r.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(phrases,columns=['score','Phrase'])\n",
    "table = table.sort_values('score',ascending=False)\n",
    "# table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
